# -*- coding: utf-8 -*-
"""tech-challenge-02-jun.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14J9Gw199vvRscJQzpFbPwOcz1wLoilZ9

# Tech challenge - Grupo 2
### Membros: Fernando Jarski (RM364678), Jorge de Souza Faleiros Filho (RM363042), Lucca Arruda Sartori (RM363728), Márcio Camargo da Silva (RM361109), Murilo Lourenço Martins (RM364680)

# Configurações

---
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
np.random.seed(42)
import os

# %matplotlib inline
import matplotlib as mpl
import matplotlib.pyplot as plt
mpl.rc('axes', labelsize=14)
mpl.rc('xtick', labelsize=12)
mpl.rc('ytick', labelsize=12)

"""# Análise da base de dados

Iremos análisar a base de dados "insurance_expandido.csv" com o objetivo de montar um modelo preditivo das tarifas cobradas pelo plano de saúde
"""

dataset = pd.read_csv("insurance_expandido.csv")

dataset.head()

"""Analisando o formato da base sabemos que ela possui 7 colunas e 6338 linhas"""

dataset.shape

"""Vamos ver agora quais os formatos de dados temos"""

dataset.info()

"""O que podemos analisar até agora é que a nossa base é constituida de 2 colunas de inteiros, 2 colunas de decimais e 3 colunas de texto e nessa base não temos valores nulos em nenhuma das colunas.

Precisamos entender agora se as colunas numericas possuem algum dado discrepante que não faça sentido para o contexto
"""

dataset.describe()

"""Como não indentificamos nenhum problema com as colunas numericas vamos analisar os valores contidos nas colunas de texto"""

set(dataset["sex"])

set(dataset["smoker"])

set(dataset["region"])

"""Como identificado todas as colunas tem valores condizentes com o contexto, agora como essas colunas não seguem uma importancia numerica vamos precisar mais a frente transformar elas em valores binarios para que o algoritimo consiga classificar, mas primeiramente vamos ver o histograma das colunas numericas e ver como os dados estão distribuidos."""

dataset.hist(bins=20, figsize=(20,15))

"""observando os histogramas é possivel observar que a coluna de charges (target) esta com os dados mal distribuidos isso mostra que teremos que tratar a divisao de dados quando formos gerar a base de treino e teste.

Vamos agora ver qual a correlação das colunas com a nossa coluna target
"""

data_encoded = pd.get_dummies(dataset, drop_first=True)

# Calcula a matriz de correlação
correlation_matrix = data_encoded.corr()

# Seleciona a correlação com a variável 'charges' e ordena
corr_with_target = correlation_matrix["charges"].sort_values(ascending=False)

corr_with_target

"""Como mostrado na tabela de correlação a coluna de smoker tem uma forte relação com a nossa coluna target portanto precisamos entender como se da a distribuição dos valores dela"""

data_encoded['smoker_yes'] = data_encoded['smoker_yes'].astype(int)

# Plotando o histograma para a coluna 'smoker_yes'
plt.figure(figsize=(6, 4))
plt.hist(data_encoded['smoker_yes'], bins=2, edgecolor='black')

# Adicionando título e rótulos
plt.title('Distribuição de Smoker')
plt.xlabel('Smoker (0 = Não, 1 = Sim)')
plt.ylabel('Frequência')

# Ajustando o espaçamento entre as barras
plt.xticks([0, 1], ['Não', 'Sim'])

# Exibindo o gráfico
plt.show()

"""Como vemos a distribuição esta bem desequilibrada portanto ser interessante estratificar quando fizermos a divisão de teste e treino

Podemos tambem ver a relação da nossa target com as outras colunas
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Suponha que 'y' seja sua variável alvo
target = 'charges'

# Para cada coluna (exceto o alvo), plote a relação
for col in data_encoded.columns:
    if col != target:
        plt.figure(figsize=(6, 4))
        sns.regplot(x=data_encoded[col], y=data_encoded[target], line_kws={'color': 'red'})
        plt.title(f'Relação entre {col} e {target}')
        plt.xlabel(col)
        plt.ylabel(target)
        plt.grid(True)
        plt.tight_layout()
        plt.show()

"""# Tratamento da base de dados e geração das base de teste e treino

Para garantir que o modelo aprenda padrões representativos, realizamos um tratamento especial na divisão dos dados em conjuntos de treino e teste.

Primeiro, categorizamos a variável target (charges) em quatro grupos de igual tamanho (quartis) usando a função pd.qcut().
"""

from sklearn.model_selection import train_test_split
# Criar a coluna de categorias com quartis
dataset["charges_cat"] = pd.qcut(dataset["charges"], q=4, labels=False)

"""Em seguida, combinamos essa categorização com a variável categórica smoker para criar uma coluna auxiliar que garante que tanto os custos quanto o status de fumante estejam distribuídos proporcionalmente em treino e teste."""

# Criar a coluna para estratificação combinando charges_cat e smoker
dataset["strat_col"] = dataset["charges_cat"].astype(str) + "_" + dataset["smoker"]

"""Usamos a técnica de split estratificado via train_test_split, que divide os dados mantendo a proporção das categorias da variável auxiliar."""

# Fazer o split estratificado usando train_test_split
train_set, test_set = train_test_split(
    dataset,
    test_size=0.2,
    random_state=42,
    stratify=dataset["strat_col"]
    )

"""Por fim, removemos as colunas auxiliares usadas para estratificação e separamos a variável alvo (charges) dos dados de entrada.

Esse procedimento assegura que ambos os conjuntos, treino e teste, reflitam a diversidade da base original, principalmente em relação a características importantes como o hábito de fumar e o nível de custos.
"""

# Remover as colunas auxiliares usadas para estratificação
train_set = train_set.drop(["charges_cat", "strat_col"], axis=1)
test_set = test_set.drop(["charges_cat", "strat_col"], axis=1)


# Separar rótulos (target)
train_labels = train_set["charges"].copy()
test_labels = test_set["charges"].copy()

# Remover target dos dados de entrada
train_set = train_set.drop("charges", axis=1)
test_set = test_set.drop("charges", axis=1)

"""Visualização das 5 primeiras linhas da base de treino.
Para verificar se as colunas foram removidas.
"""

train_set.head()

"""Vamos verificar e comparar as distribuições dos dados de treino e teste."""

plt.figure(figsize=(12, 6))
plt.hist(train_labels, bins=50, alpha=0.7, label="Train Set")
plt.hist(test_labels, bins=50, alpha=0.7, label="Test Set")
plt.title("Distribuição de Charges - Conjuntos de Treinamento e Teste")
plt.xlabel("Charges")
plt.ylabel("Frequência")
plt.legend()
plt.show()

"""Definir colunas para normalizar e colunas que precisam ser tranformados em binario.

Para Colunas com somente 2 opções utilizamos OrdinalEncoder

Para colunas de 3 ou mais utilizamos OneHotEncoder
"""

num_attribs = ["age", "bmi", "children"]
cat_label_encoder = ["sex", "smoker"]
cat_attribs_one = [ "region"]

"""Criando pipeline para transformar números e categorias"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler , OrdinalEncoder
from sklearn.impute import SimpleImputer

# Pipeline para dados numéricos
num_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("std_scaler", StandardScaler()),
])

# Pipeline completa (numéricos + categóricos)
full_pipeline = ColumnTransformer([
    ("cat", OneHotEncoder(), cat_attribs_one),
    ("cat_label", OrdinalEncoder(), cat_label_encoder),
    ("num", num_pipeline, num_attribs),
])

"""Preparar dados de treino e teste"""

train_prepared = full_pipeline.fit_transform(train_set)
test_prepared = full_pipeline.transform(test_set)

"""# Aplicação do algoritimos de análise

Escolhemos 2 modelos para testar a base de dados.

Primeiramente testamos o modelo de Regressão Linear Multipla.
O objetivo é prever um valor numérico contínuo (charges), o que é exatamente o que a regressão linear faz.

A regressão linear é simples, rápida e oferece excelente interpretabilidade.

A matriz de correlação mostra que há uma forte correlação linear entre charges e smoker, o que é ideal para esse modelo.

Serve como baseline (modelo de referência inicial) para comparar com modelos mais complexos.
Modelo de aprendizado não linear, ideal para capturar relações complexas e interações entre variáveis (ex: idade e se a pessoa fuma).
"""

from sklearn.linear_model import LinearRegression

model_lr = LinearRegression()
model_lr.fit(train_prepared, train_labels)

"""O segundo modelo que escolhemos foi o RandomForest
optamos por ele pois lida muito bem com variáveis categóricas codificadas, como sex, smoker e region. Após aplicar one-hot encoding, essas variáveis passam a representar diferentes "caminhos" nas árvores de decisão. Isso permite que o modelo capte interações complexas e não lineares entre categorias e valores contínuos, algo que a regressão linear não consegue fazer com a mesma eficácia.
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

for n in [10, 50, 60, 70, 80, 100, 200]:
    model = RandomForestRegressor(n_estimators=n, random_state=42 , )

    # Treinar o modelo PRIMEIRO para que as árvores existam
    model.fit(train_prepared, train_labels)

    # Acessar a profundidade de cada árvore
    depths = [tree.tree_.max_depth for tree in model.estimators_]

    # Calcular a profundidade média e máxima das árvores na floresta
    avg_depth = np.mean(depths)
    max_actual_depth = np.max(depths)
    min_actual_depth = np.min(depths)


    scores = cross_val_score(model, train_prepared, train_labels,
                             scoring="neg_mean_squared_error", cv=5)
    rmse_scores = np.sqrt(-scores)

    print(f"{n} árvores:")
    print(f"  Profundidade Média das Árvores: {avg_depth:.2f}")
    print(f"  Profundidade Máxima das Árvores: {max_actual_depth}")
    print(f"  Profundidade Mínima das Árvores: {min_actual_depth}")
    print(f"  RMSE médio = {rmse_scores.mean():.2f}")
    print("-" * 30)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

for n in range(5, 20):
    model = RandomForestRegressor(n_estimators=100, random_state=42 , max_depth=n)
    scores = cross_val_score(model, train_prepared, train_labels,
                             scoring="neg_mean_squared_error", cv=5)
    rmse_scores = np.sqrt(-scores)

    print(f"  RMSE médio = {rmse_scores.mean():.2f}")
    print("-" * 30)

"""Testamos quantidades de árvores com validação cruzada de 5 e percebemos que em termos de performarce e velocidade o modelo com 100 árvores atende as necessidades

Tambem testamos o numero de ramos por arvore. Deixando ele livre a arvore ficou com 23 ramos, oque pode ser muito e gerar um underfiting no nosso modelo.
Depois de testar com algumas outras quantidades foi possivel ver que um numero bom para as arvores seria de 13, pois esta com um RMSE muito proximo do de 23 e tem 10 ramos a menos.

200 árvores teve o menor RMSE médio: 2004.20 — melhor performance preditiva.

Porém, a melhora de 100 para 200 árvores foi pequena (2010.80 → 2004.20), só ~6 pontos de RMSE.

Considerando custo computacional, tempo de treinamento e ganhos marginais, um número entre 100 e 200 árvores é um bom compromisso.

Para um modelo mais rápido, 100 árvores já entrega resultado muito próximo do melhor.
"""

model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=13)
model.fit(train_prepared, train_labels)

"""# Análise estatisca dos resultados

###Resultado da Regressão Linear.
"""

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error
import numpy as np

# Previsões no conjunto de teste
predictions = model_lr.predict(test_prepared)

# R²
r2 = r2_score(test_labels, predictions)

# RMSE
rmse = np.sqrt(mean_squared_error(test_labels, predictions))

# MAPE
mape = mean_absolute_percentage_error(test_labels, predictions)

print(f"R²: {r2:.4f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.4%}")

"""Ao aplicar o modelo de regressão para prever os custos de seguro de saúde, obtivemos um erro médio (RMSE) de aproximadamente R$ 5.000.

Esse valor monetário é alto e representa cerca de 34% do valor real médio dos custos. Isso significa que o modelo, em média, erra quase um terço do valor que deveria prever — o que pode ser um problema sério, especialmente em decisões financeiras.

##Resultado do RandomForest
"""

# Previsões
train_predictions = model.predict(train_prepared)
test_predictions = model.predict(test_prepared)

# Avaliar o modelo
r2 = r2_score(test_labels, test_predictions)
rmse = np.sqrt(mean_squared_error(test_labels, test_predictions))
mape = mean_absolute_percentage_error(test_labels, test_predictions)

# Resultados
print(f"R²: {r2:.4f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.4%}")

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_percentage_error
import numpy as np

# Previsões usando validação cruzada
cv_predictions = cross_val_predict(model, train_prepared, train_labels, cv=5)

# Avaliar o modelo
r2 = r2_score(train_labels, cv_predictions)
rmse = np.sqrt(mean_squared_error(train_labels, cv_predictions))
mape = mean_absolute_percentage_error(train_labels, cv_predictions)

# Resultados
print(f"R² (cross-val): {r2:.4f}")
print(f"RMSE (cross-val): {rmse:.2f}")
print(f"MAPE (cross-val): {mape:.4%}")

"""Fizemos o teste com todas a linhas e tambem com a validação cruzada para observar como os indicadores se comportam.

O modelo Random Forest se mostrou mais eficiente para este problema de regressão, apresentando baixo erro absoluto e percentual, além de uma alta explicabilidade da variância.
Visto que o o valor do RMSE de aproximadamente
R$ 1.992 representa menos de 50% do valor previsto pela Regressão Linear, tornando este modelo mais eficiente e preciso.

# Análise gráfica dos resultados

Comparativos das previsões com os dados reais.
"""

plt.figure(figsize=(8, 6))
plt.scatter(test_labels, predictions, alpha=0.6, color='blue', label='Previsões')
plt.plot([test_labels.min(), test_labels.max()], [test_labels.min(), test_labels.max()], 'r--', lw=2, label='Ideal')
plt.xlabel('Valor Real')
plt.ylabel('Valor Previsto')
plt.title('Valores Reais vs. Valores Previstos (Linear Regression)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(test_labels, test_predictions, alpha=0.6, color='blue', label='Previsões')
plt.plot([test_labels.min(), test_labels.max()], [test_labels.min(), test_labels.max()], 'r--', lw=2, label='Ideal')
plt.xlabel('Valor Real')
plt.ylabel('Valor Previsto')
plt.title('Valores Reais vs. Valores Previstos (Random Forest)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""Comparando os graficos é possivél observar visualmente como o modelo de Random Forest foi mais eficiente em prever os dados que o de Regreção Linear. O Forest se aproxima muito da linha normal(Ideal).

Ainda é possível ver que o modelo de Random Forest generalizou bem a base e não decorou os dados, pois ele teve uma pequena margem de erro, que representa a sua capacidade de prever dados não vistos com boa precisão, mantendo o equilíbrio entre viés e variância. Isso indica que o modelo aprendeu padrões relevantes dos dados de treino sem superajustar.
"""